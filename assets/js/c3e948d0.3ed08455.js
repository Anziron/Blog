"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[848],{7352:(r,n,e)=>{e.r(n),e.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>p,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"machine_learning/traditional_algorithm/logistic_regression","title":"\u903b\u8f91\u56de\u5f52","description":"\u8bf4\u660e\uff1a","source":"@site/docs/machine_learning/traditional_algorithm/logistic_regression.md","sourceDirName":"machine_learning/traditional_algorithm","slug":"/machine_learning/traditional_algorithm/logistic_regression","permalink":"/docs/machine_learning/traditional_algorithm/logistic_regression","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"\u7ebf\u6027\u56de\u5f52","permalink":"/docs/machine_learning/traditional_algorithm/linear_regression"},"next":{"title":"\u51b3\u7b56\u6811","permalink":"/docs/machine_learning/traditional_algorithm/decision_tree"}}');var t=e(4848),i=e(8453);const l={},a="\u903b\u8f91\u56de\u5f52",o={},d=[{value:"\u8bf4\u660e\uff1a",id:"\u8bf4\u660e",level:2},{value:"\u903b\u8f91\u56de\u5f52\u539f\u7406\u4ee3\u7801",id:"\u903b\u8f91\u56de\u5f52\u539f\u7406\u4ee3\u7801",level:2},{value:"\u4f7f\u7528sklearn\u6a21\u5757",id:"\u4f7f\u7528sklearn\u6a21\u5757",level:2},{value:"\u5b9e\u6218\u793a\u4f8b",id:"\u5b9e\u6218\u793a\u4f8b",level:2}];function c(r){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...r.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"\u903b\u8f91\u56de\u5f52",children:"\u903b\u8f91\u56de\u5f52"})}),"\n",(0,t.jsx)(n.h2,{id:"\u8bf4\u660e",children:"\u8bf4\u660e\uff1a"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"\u7528\u9014"}),"\uff1a\u9884\u6d4b\u4e00\u4e2a\u4e8b\u4ef6\u662f\u5426\u53d1\u751f\uff0c\u6216\u8005\u662f\u4e0d\u662f\u67d0\u4e2a\u7c7b\u522b\uff08\u5373\u5206\u7c7b\u95ee\u9898\uff0c\u5c24\u5176\u662f",(0,t.jsx)(n.strong,{children:"\u4e8c\u5206\u7c7b"}),"\uff09\u3002"]}),"\n",(0,t.jsx)(n.p,{children:"\u6bd4\u5982\uff1a"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u90ae\u4ef6\u662f\u4e0d\u662f\u5783\u573e\u90ae\u4ef6\uff08\u662f/\u4e0d\u662f\uff09"}),"\n",(0,t.jsx)(n.li,{children:"\u7528\u6237\u662f\u5426\u4f1a\u8d2d\u4e70\u5546\u54c1"}),"\n",(0,t.jsx)(n.li,{children:"\u4e00\u5f20\u56fe\u7247\u662f\u4e0d\u662f\u732b"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"\u6a21\u578b\u5f62\u5f0f"}),"\uff1a"]}),"\n",(0,t.jsx)(n.p,{children:'\u903b\u8f91\u56de\u5f52\u5148\u7b97\u4e00\u4e2a\u7ebf\u6027\u7ec4\u5408\u7684\u503c\uff0c\u518d\u901a\u8fc7\u4e00\u4e2a sigmoid \u51fd\u6570\u628a\u503c"\u538b\u7f29"\u5230 0~1 \u4e4b\u95f4\uff0c\u53d8\u6210\u6982\u7387\u5982\u679c\u7ed3\u679c\u5927\u4e8e 0.5\uff0c\u901a\u5e38\u5c31\u9884\u6d4b\u662f"1\u7c7b"\uff0c\u5426\u5219\u662f"0\u7c7b"\u3002'}),"\n",(0,t.jsx)(n.h2,{id:"\u903b\u8f91\u56de\u5f52\u539f\u7406\u4ee3\u7801",children:"\u903b\u8f91\u56de\u5f52\u539f\u7406\u4ee3\u7801"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# \u516c\u5f0fy = wx + b\r\n# w\u4e3a\u6743\u91cd\uff0cb\u4e3a\u504f\u7f6e\u503c\r\n\r\nimport numpy as np\r\nfrom matplotlib import pyplot as plt\r\n\r\nclass Sline:\r\n    def __init__(self):\r\n        # \u8bbe\u7f6e\u521d\u59cb\u7684w\u4e0eb\r\n        self.w = 0\r\n        self.b = 0\r\n\r\n        # \u8bbe\u7f6e\u6bcf\u6b21\u79fb\u52a8\u7684\u89d2\u5ea6,\u7cbe\u786e\u5ea6\r\n        self.learn_rate = 0.01\r\n\r\n        # \u521b\u5efa\u4e00\u4e2a\u4e24\u884c\u4e00\u5217\u7684\u7a97\u53e3\u548c\u4e24\u4e2a\u753b\u5e03\r\n        self.fig, (self.ax1, self.ax2) = plt.subplots(2, 1)\r\n\r\n        # \u521b\u5efa\u4e00\u4e2a\u83b7\u53d6\u635f\u5931\u503c\u7684\u6570\u7ec4\r\n        self.loss_list = []\r\n\r\n    # \u83b7\u53d6\u4f20\u5165\u7684\u6570\u636e,\u6563\u70b9\r\n    def get_data(self, data):\r\n        # \u83b7\u53d6\u6570\u636e\u7684\u521d\u59cbx\u4e0ey\r\n        self.X = np.array(data)[:,0]\r\n        self.y = np.array(data)[:,1]\r\n\r\n    # \u5c06\u51fd\u6570\u7ec4\u5408\r\n    def predict(self, x):\r\n        return 1 / (1 + np.exp(-(self.w * x + self.b)))\r\n\r\n    # \u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u63d0\u4f9b\u8bad\u7ec3\u6b21\u6570\r\n    def train(self, epoch_times):\r\n        for epoch in range(epoch_times):\r\n            # \u7edf\u8ba1\u635f\u5931\u6b21\u6570\r\n            totle_loss = 0\r\n\r\n            # \u904d\u5386\u6570\u636e\u4e2d\u6240\u6709\u5bf9\u5e94\u7684x\u4e0ey\r\n            for x, y in zip(self.X, self.y):\r\n                # \u8ba1\u7b97\u5728\u51fd\u6570\u4e0a\u7684y\u503c\r\n                y_pred = self.predict(x)\r\n\r\n                # \u81ea\u6c42\u5bfc,\u6c42\u51fa\u5f53\u524dw\u4e0eb\r\n                grad = -2 * (y - y_pred) * (1 - y_pred) * y_pred * x\r\n\r\n                # \u66f4\u65b0\u65b0\u7684w\u4e0eb\r\n                self.w -= self.learn_rate * grad * x\r\n                self.b -= self.learn_rate * grad\r\n\r\n                # \u8ba1\u7b97\u5747\u503c\u65b9\u5dee,\u4f7f\u7528\u539fy\u503c\u51cf\u53bb\u5728\u51fd\u6570\u4e0a\u7684y\u503c\uff0c\u8ba1\u7b97\u635f\u5931\u503ce\r\n                loss = (y - y_pred) ** 2\r\n                totle_loss += loss\r\n            epoch_loss = totle_loss / len(self.X)\r\n            self.loss_list.append(epoch_loss)\r\n            # \u8bad\u7ec310\u6b21\u540e\u6253\u5370\u8bad\u7ec3\u5341\u6b21\u540e\u7684\u7f3a\u5931\u503c\r\n            if epoch % 10 == 0:\r\n                print(f"loss: {epoch_loss}")\r\n                self.plot()\r\n        plt.ioff()\r\n        plt.show()\r\n  \r\n    def plot(self):\r\n        plt.ion()\r\n        self.ax1.clear()\r\n        self.ax2.clear()\r\n        x = np.linspace(0, 10, 100)\r\n        self.ax1.scatter(self.X, self.y, c = "g")\r\n        self.ax1.plot(x, self.predict(x), c = "b")\r\n        self.ax2.plot(list(range(len(self.loss_list))), self.loss_list)\r\n        plt.show()\r\n        plt.pause(0.1)\r\n\r\nif __name__ == \'__main__\':\r\n    data = [(1, 0), (1.8, 0), (2.5, 0), (4.2, 1), (5, 1), (6, 1), (7, 1)]\r\n    s = Sline()\r\n    s.get_data(data)\r\n    s.train(1000)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"\u4f7f\u7528sklearn\u6a21\u5757",children:"\u4f7f\u7528sklearn\u6a21\u5757"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'"""\r\n @Author: Anziron\r\n @Email: 1312235991@qq.com\r\n @FileName: 04-\u903b\u8f91\u56de\u5f52sklearn.py\r\n @DateTime: 2025/04/11 16:13\r\n @SoftWare: VSCode\r\n"""\r\n\r\nfrom sklearn import datasets\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom sklearn.linear_model import LogisticRegression\r\n\r\n# \u52a0\u8f7d\u6570\u636e\u96c6,\u624b\u5199\u6570\u636e\u96c6\r\ndigits = datasets.load_digits()\r\n# \u83b7\u53d6\u7279\u5f81\u548c\u76ee\u6807\u53d8\u91cf\r\nX = digits.data\r\ny = digits.target\r\n\r\n# \u6570\u636e\u9884\u5904\u7406\uff1a\u968f\u673a\u5206\u5272\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 , \u5982\u679c\u4e0d\u6307\u5b9a random_state\uff0c\u6bcf\u6b21\u8fd0\u884c\u7ed3\u679c\u90fd\u4e0d\u4e00\u6837\u300242\u4e3a\u7ea6\u5b9a\u4fd7\u6210\u7684\u968f\u673a\u6570\u79cd\u5b50\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n\r\n# \u6570\u636e\u6807\u51c6\u5316\r\nscaler = StandardScaler()\r\n# .fit_transform()\u65b9\u6cd5\u5148\u62df\u5408\u6570\u636e\uff0c\u518d\u6807\u51c6\u5316\u3002\u548c\u964d\u7ef4\u7b97\u6cd5\u7684\u8bed\u6cd5\u4e00\u81f4\r\nX_train = scaler.fit_transform(X_train)\r\n# .transform()\u65b9\u6cd5\u76f4\u63a5\u4f7f\u7528\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6807\u51c6\u5316\u64cd\u4f5c\r\nX_test = scaler.transform(X_test)\r\n\r\n# \u521b\u5efaLogistic Regression\u6a21\u578b  , \u5982\u679c\u4e0d\u6307\u5b9a random_state\uff0c\u6bcf\u6b21\u8fd0\u884c\u7ed3\u679c\u90fd\u4e0d\u4e00\u6837\u300242\u4e3a\u7ea6\u5b9a\u4fd7\u6210\u7684\u968f\u673a\u6570\u79cd\u5b50\r\nmodel = LogisticRegression(random_state=42)\r\n\r\n# .fit()\u65b9\u6cd5\u7528\u4e8e\u62df\u5408\u6a21\u578b\uff0c\u5373\u8bad\u7ec3\u6a21\u578b\r\nmodel.fit(X_train, y_train)\r\n\r\n# .predict()\u65b9\u6cd5\u9884\u6d4b\u65b0\u6570\u636e\u70b9\u7684\u7c7b\u522b\r\ny_pred = model.predict(X_test)\r\n\r\nfrom sklearn.metrics import accuracy_score\r\n\r\n# accuracy_score()\u65b9\u6cd5\u8ba1\u7b97\u51c6\u786e\u7387\r\naccuracy = accuracy_score(y_test, y_pred)\r\nprint(f\'Accuracy: {accuracy}\')\r\n\r\nfrom matplotlib import pyplot as plt\r\n# \u9009\u51fa\u9884\u6d4b\u9519\u8bef\u7684\u6837\u672c\r\nindex = []\r\n# \u904d\u5386\u6240\u6709\u6837\u672c\r\nfor i in range(len(y_pred)):\r\n    # \u5224\u65ad\u662f\u5426\u76f8\u7b49\r\n    if y_pred[i] != y_test[i]:\r\n        # \u5982\u679c\u4e0d\u76f8\u7b49,\u6dfb\u52a0\u5230index\u4e2d:\u9884\u6d4b\u503c,\u771f\u5b9e\u503c,\u56fe\u7247(\u6ce8\u610f\u8981\u53d8\u6362\u5f62\u72b6\u4e3a8*8)\r\n        index.append((\r\n                    y_pred[i],\r\n                    y_test[i],\r\n                    X_test[i].reshape((8, 8))))\r\n\r\n# \u521b\u5efa\u4e00\u4e2a\u6b63\u65b9\u5f62\u753b\u5e03\r\n# nrows:\u5b50\u56fe\u7684\u884c\u6570\r\n# ncols:\u5b50\u56fe\u7684\u5217\u6570\r\n# print(len(index)) // 10\r\n# \u56e0\u4e3a\u4e00\u5171\u670910\u5f20\u56fe\u7247,\u6240\u4ee5\u884c\u6570\u4e3a2,\u5217\u6570\u4e3a5\uff0c\u53732*5=10\r\nfig, ax = plt.subplots(\r\n    nrows=3,\r\n    ncols=5,\r\n)\r\n# \u5b9e\u4f8b\u5316\u5b50\u753b\u5e03\r\nax = ax.flatten()\r\nfor i in range(len(index)):\r\n    p = index[i][0] # \u53d6\u51fa\u9884\u6d4b\u503c\r\n    a = index[i][1] # \u53d6\u51fa\u771f\u5b9e\u503c\r\n    img = index[i][2] # \u53d6\u51fa\u56fe\u7247\r\n    # \u5728\u5b50\u753b\u5e03\u4e0a\u753b\u51fa\u56fe\u7247\uff0c\u683c\u5f0f\u4e3a\u7070\u5ea6\u56fe\r\n    ax[i].imshow(img)\r\n    ax[i].set_title(f\'{p}-{a}\')\r\nplt.show()\n'})}),"\n",(0,t.jsx)(n.h2,{id:"\u5b9e\u6218\u793a\u4f8b",children:"\u5b9e\u6218\u793a\u4f8b"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from sklearn.linear_model import LogisticRegression\r\n\r\n# \u7279\u5f81\r\nX = [\r\n    [5.2, 30, 8],\r\n    [10.5, 50, 12],\r\n    [2.3, 20, 10],\r\n    [0.9, 10, 2]\r\n]\r\n\r\n# \u6807\u7b7e\uff08\u591a\u4e2a\u7c7b\u522b\uff09\r\ny = ['\u732b', '\u72d7', '\u5154\u5b50', '\u9e1f']\r\n\r\n# \u6a21\u578b\u8bad\u7ec3\r\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\r\nmodel.fit(X, y)\r\n\r\n# \u65b0\u52a8\u7269\u8bc6\u522b\r\nnew_animal = [[4.5, 25, 7],[2, 3, 4]]\r\npred = model.predict(new_animal)\r\n# \u5185\u7f6eSoftmax,\u4f1a\u5c06\u65b0\u9884\u6d4b\u503c\u4f20\u5165\u8bad\u7ec3\u597d\u7684\u516c\u5f0f\u4e2d\r\n# \u5c06\u6bcf\u4e00\u4e2ay\u6c42\u51fa\u6765\u8fdb\u884c\u6982\u7387\u5224\u65ad\r\n# \u9009\u62e9\u6700\u5927\u6982\u7387\u8fd4\u56de\r\nprint(\"\u9884\u6d4b\u7ed3\u679c\u662f\uff1a\", pred[0])\r\nprint(\"\u9884\u6d4b\u7ed3\u679c\u662f\uff1a\", pred[1])\n"})})]})}function p(r={}){const{wrapper:n}={...(0,i.R)(),...r.components};return n?(0,t.jsx)(n,{...r,children:(0,t.jsx)(c,{...r})}):c(r)}},8453:(r,n,e)=>{e.d(n,{R:()=>l,x:()=>a});var s=e(6540);const t={},i=s.createContext(t);function l(r){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof r?r(n):{...n,...r}},[n,r])}function a(r){let n;return n=r.disableParentContext?"function"==typeof r.components?r.components(t):r.components||t:l(r.components),s.createElement(i.Provider,{value:n},r.children)}}}]);